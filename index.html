<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Risk-Calibrated Human-Robot Interaction via Set-Valued Intent Prediction </title>

    <meta name="description" content="Risk-Calibrated Human-Robot Interaction via Set-Valued Intent Prediction">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <!-- <link rel="icon" type="image/png" href="img/seal_icon.png"> -->

    <link href="//cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/styles/default.min.css">
    <link rel="stylesheet" href="css/app.css">

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/highlight.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
	
    <style>
        .nav-pills {
          position: relative;
          display: inline;
        }
        .imtip {
          position: absolute;
          top: 0;
          left: 0;
        }
    </style>
</head>
<body>
    <div class="container" id="main">
        <div class="row mt-4">
            <h2 class="col-md-12 text-center">
                Risk-Calibrated Human-Robot Interaction via Set-Valued Intent Prediction </br>
            </h2>
        </div>
        
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <br>
                    <li><a href="https://jlidard.github.io">Justin Lidard</a></li>
                    <li><a href="https://www.linkedin.com/in/hangp/">Hang Pham</a></li>
                    <li><a href="https://www.linkedin.com/in/ariel-bachman/">Ariel Bachman</a></li>
                    <li><a href="https://www.linkedin.com/in/bryan-boateng/">Bryan Boateng</a></li>
                    <li><a href="https://irom-lab.princeton.edu/majumdar/">Anirudha Majumdar</a></li>
                </ul>
            </div>
        </div>

        <div class="row justify-content-md-center">
            <div class="col-md-2 text-center">
                <a href="https://arxiv.org/pdf/2403.15959.pdf">
                <image src="img/paper_small.png" height="110px" width="85px">
                <h4><strong>Paper</strong></h4>
                </a>
            </div>
            <div class="col-md-2 text-center">
                <a href="https://github.com/irom-lab/risk_calibrated_interactive_planning>">
                <image src="img/github.png"  height="110px">
                <h4><strong>Code</strong></h4>
                </a>
            </div>
        </div>


        <div class="row justify-content-md-center">
            <div class="col-md-10 col-lg-8">
                <h3 class="mt-4 mb-2">
                    Abstract
                </h3>
                <p class="text-justify">
                    Tasks where robots must cooperate with humans, such as navigating around a cluttered home or sorting
                    everyday items, are challenging because they exhibit a wide range of valid actions that lead to
                    similar outcomes. Moreover, zero-shot cooperation between human-robot partners is an especially
                    challenging problem because it requires the robot to infer and adapt on the fly to a latent human intent,
                    which could vary significantly from human to human. Recently, deep learned motion prediction models
                    have shown promising results in predicting human intent but are prone to being confidently incorrect.
                    In this work, we present Risk-Calibrated Interactive Planning (RCIP), which is a framework for measuring
                    and calibrating risk associated with uncertain action selection in human-robot cooperation, with the
                    fundamental idea that the robot should ask for human clarification when the risk associated with the
                    uncertainty in the human's intent cannot be controlled. RCIP builds on the theory of set-valued risk
                    calibration to provide a finite-sample statistical guarantee on the cumulative loss incurred by the
                    robot while minimizing the cost of human clarification in complex multi-step settings. Our main insight
                    is to frame the risk control problem as a sequence-level multi-hypothesis testing problem, allowing
                    efficient calibration using a low-dimensional parameter that controls a pre-trained risk-aware policy.
                    Experiments across a variety of simulated and real-world environments demonstrate RCIP's ability to
                    predict and adapt to a diverse set of dynamic human intents.
                </p>
                <p style="text-align:center;">
                    <image src="img/share_image.png" width="100%">
                </p>
                <div class="col-md-12">
                    <video id="v0" width="100%" preload="metadata" playsinline controls>
                        <source src="videos/rcip_compressed.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>
    </div>
</body>
</html>
