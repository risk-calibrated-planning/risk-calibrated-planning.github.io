<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Risk-Calibrated Human-Robot Interaction via Set-Valued Intent Prediction </title>

    <meta name="description" content="Risk-Calibrated Human-Robot Interaction via Set-Valued Intent Prediction">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <!-- <link rel="icon" type="image/png" href="img/seal_icon.png"> -->

    <link href="//cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/styles/default.min.css">
    <link rel="stylesheet" href="css/app.css">

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/highlight.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
	
    <style>
        .nav-pills {
          position: relative;
          display: inline;
        }
        .imtip {
          position: absolute;
          top: 0;
          left: 0;
        }
    </style>
</head>
<body>
    <div class="container" id="main">
        <div class="row mt-4">
            <h2 class="col-md-12 text-center">
                Risk-Calibrated Human-Robot Interaction via Set-Valued Intent Prediction </br>
            </h2>
        </div>
        
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <br>
                    <li><a href="https://jlidard.github.io">Justin Lidard</a></li>
                    <li><a href="https://www.linkedin.com/in/hangp/">Hang Pham</a></li>
                    <li><a href="https://www.linkedin.com/in/ariel-bachman/">Ariel Bachman</a></li>
                    <li><a href="https://www.linkedin.com/in/bryan-boateng/">Bryan Boateng</a></li>
                    <li><a href="https://irom-lab.princeton.edu/majumdar/">Anirudha Majumdar</a></li>
                </ul>
            </div>
        </div>

        <div class="row justify-content-md-center">
            <image src="img/irom_lab.png" height="55px" ></image>
            <image src="img/PU1line.svg" height="110px" ></image>
        </div>

        <div class="row justify-content-md-center">
            <h3 class="mt-4 mb-2">
                RSS 2024
            </h3>
        </div>

        <div class="row justify-content-md-center">
            <div class="col-md-2 text-center">
                <a href="https://arxiv.org/pdf/2403.15959.pdf">
                    <image src="img/paper.png" height="110px" width="85px"></image>
                <h4><strong>Paper</strong></h4>
                </a>
            </div>
            <div class="col-md-2 text-center">
                <a href="https://github.com/irom-lab/risk_calibrated_interactive_planning">
                <image src="img/github.png"  height="110px"></image>
                <h4><strong>Code</strong></h4>
                </a>
            </div>
            <div class="col-md-2 text-center">
                <a href="https://drive.google.com/drive/folders/13qAaPCHEcx93BTcPwwXSITSm7LKsAohr?usp=sharing">
                <image src="img/database.png"  height="110px"></image>
                <h4><strong>
                    Dataset
                </strong></h4>
                </a>
            </div>
        </div>

        <div class="row justify-content-md-center">
            <div class="col-md-10 col-lg-8">
                <h3 class="mt-4 mb-2">
                    Goal
                </h3>
                <p class="text-justify">
                    In the setting of the robot with access to an intent prediction model (e.g., a VLM) and human help,
                    we aim to achieve both: (1) risk calibration: the robot should seek sufficient help to ensure a
                    statistically guaranteed level of task success specified by the user while also satisfying
                    a limit on the human help rate, and (2) flexible autonomy: the robot should be able to tune its
                    behavior (e.g., fewer errors with more help) by providing a range of prediction parameters that control
                    its level of risk. We collectively refer to these sufficiency and minimality conditions as certifiable autonomy.
                </p>
            </div>
        </div>

        <div class="row justify-content-md-center">
            <div class="col-md-10 col-lg-8">
                <h3 class="mt-4 mb-2">
                    Abstract
                </h3>
                <p class="text-justify">
                    Tasks where robots must cooperate with humans, such as navigating around a cluttered home or sorting
                    everyday items, are challenging because they exhibit a wide range of valid actions that lead to
                    similar outcomes. Moreover, zero-shot cooperation between human-robot partners is an especially
                    challenging problem because it requires the robot to infer and adapt on the fly to a latent human intent,
                    which could vary significantly from human to human. Recently, deep learned motion prediction models
                    have shown promising results in predicting human intent but are prone to being confidently incorrect.
                    In this work, we present Risk-Calibrated Interactive Planning (RCIP), which is a framework for measuring
                    and calibrating risk associated with uncertain action selection in human-robot cooperation, with the
                    fundamental idea that the robot should ask for human clarification when the risk associated with the
                    uncertainty in the human's intent cannot be controlled. RCIP builds on the theory of set-valued risk
                    calibration to provide a finite-sample statistical guarantee on the cumulative loss incurred by the
                    robot while minimizing the cost of human clarification in complex multi-step settings. Our main insight
                    is to frame the risk control problem as a sequence-level multi-hypothesis testing problem, allowing
                    efficient calibration using a low-dimensional parameter that controls a pre-trained risk-aware policy.
                    Experiments across a variety of simulated and real-world environments demonstrate RCIP's ability to
                    predict and adapt to a diverse set of dynamic human intents.
                </p>
                <p style="text-align:center;">
                    <image src="img/fig1.png" width="60%"></image>
<!--                    <embed type="application/pdf" src="img/figure1_tricolumn-compressed.pdf"></embed>-->
                </p>
                <div class="col-md-12">
                    <video id="v0" width="60%" preload="metadata" playsinline controls>
                        <source src="videos/rcip_compressed.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>

        <div class="row justify-content-md-center">
            <div class="col-md-10 col-lg-8">
                <h3 class="mt-4 mb-2">
                    Approach
                </h3>
                <p class="text-justify">
                    RCIP builds upon statistical risk calibration (SRC) to formally quantify and bound multiple notions of
                    risk in human-robot interaction (HRI).  Using a small set of calibration scenarios, RCIP computes step-wise prediction
                    losses to form an aggregate emperical risk estimate. Using a risk limit, for each pair (λ,θ) of prediction thresholds
                    and tunable model parameters, RCIP evaluates the hypothesis that the test set risk is above the limit.
                    Thus, for all hypotheses that are rejected, the test set risk satisfies the threshold (with high probability).
                </p>
                <p style="text-align:center;">
                    <image src="img/fig2.png" width="60%"></image>
<!--                    <embed type="application/pdf" src="img/figure1_tricolumn-compressed.pdf"></embed>-->
                </p>
                <p style="text-align:center;">
                    <image src="img/fig4.png" width="60%"></image>
<!--                    <embed type="application/pdf" src="img/figure1_tricolumn-compressed.pdf"></embed>-->
                </p>
                <p class="text-justify">
                    (Left, Center) Multi-step RCIP is applied in Social Navigation. The human’s trajectory is shown in pink, and the
                    robot’s trajectory is shown in blue. The human’s possible goal objects are shown in orange. (Right) Single-step RCIP is applied
                    in Bimanual Sorting. KnowNo, which generates plans in open-ended language, may generate a plan that is technically correct,
                    but ambiguous to execute for a language-conditioned policy (both the blue and white bin have a pot). RCIP instead guarantees
                    that the human’s intent is satisfied via constraint satisfaction with the intent-conditioned planner
                </p>

            </div>
        </div>
    </div>
</body>
</html>
